<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mission &mdash; ZetaBank - Instructor Version</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/toc_custom.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sphinxcontrib-images/LightBox2/lightbox2/dist/css/lightbox.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/toc_custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinxcontrib-images/LightBox2/lightbox2/dist/js/lightbox-plus-jquery.min.js"></script>
        <script src="../../../_static/sphinxcontrib-images/LightBox2/lightbox2-customize/jquery-noconflict.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Discussion" href="5.discussion.html" />
    <link rel="prev" title="Coding Explanation" href="3.coding_explanation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> Instructors Version
            <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.1.3
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../0.intro/explanation.html">Overall Lecture Explanation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../0.intro/mission.html">Introductory Mission</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">One-day Lecture</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../1.driving_ex/index.html">Driving the Robot Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../1.driving_ex/1.follow_along.html">Follow Along!</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../1.driving_ex/1.follow_along.html#movement-instructions">Movement Instructions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../1.driving_ex/1.follow_along.html#movement-with-odometry-information">Movement with Odometry Information</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../1.driving_ex/2.explanation.html">Explanation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../1.driving_ex/2.explanation.html#odometry-information">Odometry Information</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../1.driving_ex/3.coding_explanation.html">Coding Explanation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../1.driving_ex/3.coding_explanation.html#robot-movement">Robot Movement</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../1.driving_ex/3.coding_explanation.html#initialization">Initialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../1.driving_ex/3.coding_explanation.html#sending-commands">Sending commands</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../1.driving_ex/3.coding_explanation.html#combining-the-movement-instructions-to-a-single-python-function">Combining the movement instructions to a single python function</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../1.driving_ex/3.coding_explanation.html#odometry-information">Odometry Information</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../1.driving_ex/3.coding_explanation.html#odometry-calculation">Odometry calculation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../1.driving_ex/3.coding_explanation.html#starting-the-calculation">Starting the Calculation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../1.driving_ex/4.mission.html">Mission Project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1.driving_ex/5.discussion.html">Discussion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../1.driving_ex/qa.html">Q&amp;A session</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">AI Training Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../googlenet/index.html">AI Image Recognition using GoogleNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../googlenet/1.follow_along.html">Follow Along!</a></li>
<li class="toctree-l3"><a class="reference internal" href="../googlenet/2.explanation.html">Overall Explanation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../googlenet/2.explanation.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../googlenet/2.explanation.html#googlenet">GoogleNet</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../googlenet/3.coding_explanation.html">Coding Explanation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../googlenet/4.mission.html">Mission</a></li>
<li class="toctree-l3"><a class="reference internal" href="../googlenet/5.discussion.html">Discussion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../alexnet/index.html">AI Image Recognition using AlexNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../alexnet/1.follow_along.html">Follow Along!</a></li>
<li class="toctree-l3"><a class="reference internal" href="../alexnet/2.explanation.html">Overall Explanation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../alexnet/2.explanation.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../alexnet/2.explanation.html#alexnet">AlexNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../alexnet/2.explanation.html#how-are-googlenet-and-alexnet">How are GoogleNet and AlexNet?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../alexnet/3.coding_explanation.html">Coding Explanation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../alexnet/4.mission.html">Mission</a></li>
<li class="toctree-l3"><a class="reference internal" href="../alexnet/5.discussion.html">Discussion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../do_it_together.html">Mission Project</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../do_it_together.html#writing-python-program-as-a-team">Writing Python Program as a Team</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../pose/index.html">Body Pose Estimation with Pose-ResNet18-Body</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../pose/1.follow_along.html">Follow Along!</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pose/2.explanation.html">Overall Explanation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../pose/2.explanation.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pose/2.explanation.html#pose-resnet18-body">Pose-ResNet18-Body</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../pose/3.coding_explanation.html">Coding Explanation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../pose/3.coding_explanation.html#major-functionalities">Major Functionalities</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pose/3.coding_explanation.html#minor-functionalities">Minor Functionalities</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../pose/4.mission.html">Mission</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../pose/4.mission.html#writing-custom-posenet-program">Writing Custom poseNet Program</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pose/4.mission.html#executing-the-custom-program">Executing the Custom Program</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pose/4.mission.html#let-s-change-the-overlay">Let’s Change the Overlay!!!</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../pose/5.discussion.html">Discussion</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Sematic Segmentation with FCN-ResNet18</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="1.follow_along.html">Follow Along!</a><ul>
<li class="toctree-l4"><a class="reference internal" href="1.follow_along.html#cityscapes">CityScapes</a></li>
<li class="toctree-l4"><a class="reference internal" href="1.follow_along.html#outdoor-off-road">Outdoor (off-road)</a></li>
<li class="toctree-l4"><a class="reference internal" href="1.follow_along.html#segmenting-human-images">Segmenting Human Images</a></li>
<li class="toctree-l4"><a class="reference internal" href="1.follow_along.html#variaty-objects-and-people">Variaty Objects and People</a></li>
<li class="toctree-l4"><a class="reference internal" href="1.follow_along.html#in-doors">In-Doors</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="2.explanation.html">Overall Explanation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="2.explanation.html#overview">Overview</a></li>
<li class="toctree-l4"><a class="reference internal" href="2.explanation.html#fcn-resnet18">FCN-ResNet18</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="3.coding_explanation.html">Coding Explanation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="3.coding_explanation.html#major-functionalities">Major Functionalities</a></li>
<li class="toctree-l4"><a class="reference internal" href="3.coding_explanation.html#minor-functionalities">Minor Functionalities</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Mission</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#writing-custom-segnet-program">Writing Custom segNet Program</a></li>
<li class="toctree-l4"><a class="reference internal" href="#executing-the-custom-program">Executing the Custom Program</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="5.discussion.html">Discussion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../qa.html">Q&amp;A session</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../3.robot_control/index.html">Robot Controls Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../3.robot_control/ros_topic_control/index.html">ROS Topic Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../3.robot_control/ros_topic_control/1.follow_along/index.html">Follow Along!</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/ros_topic_control/1.follow_along/1.publisher.html">ROS Topic Publisher</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/ros_topic_control/1.follow_along/2.subscriber.html">ROS Topic Subscriber</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../3.robot_control/ros_topic_control/2.explanation/index.html">Explanation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/ros_topic_control/2.explanation/index.html#topic">Topic</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/ros_topic_control/2.explanation/index.html#nodes">Nodes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/ros_topic_control/2.explanation/index.html#publisher">Publisher</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/ros_topic_control/2.explanation/index.html#subscriber">Subscriber</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../3.robot_control/robot_sensors/index.html">ROS Sensors Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../3.robot_control/robot_sensors/1.follow_along/index.html">Follow Along!</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/robot_sensors/1.follow_along/imu.html">IMU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/robot_sensors/1.follow_along/lidar.html">LIDAR</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../3.robot_control/robot_sensors/2.explanation/index.html">Explanation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/robot_sensors/2.explanation/index.html#imu">IMU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../3.robot_control/robot_sensors/2.explanation/index.html#lidar">LIDAR</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../3.robot_control/mission.html">Mission</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../3.robot_control/mission.html#accessing-isaac-sight">Accessing Isaac Sight</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../3.robot_control/mission.html#checking-visuals">Checking Visuals</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../3.robot_control/discussion.html">Discussion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../3.robot_control/qa.html">Q&amp;A session</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../4.slam_nav/index.html">SLAM and Navigation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../4.slam_nav/basic.html">Basic Features</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/basic.html#map">1. Map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/basic.html#pose-of-robot">1. Pose of Robot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/basic.html#sensing">Sensing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/basic.html#path-calculation-and-driving">Path Calculation and Driving</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../4.slam_nav/theory.html">Theory</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/slam_theory.html">Slam  Theory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../4.slam_nav/slam_theory.html#particle-filter">Particle filter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/navigation_theory.html">Navigation Theory</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../4.slam_nav/navigation_theory.html#costmap">Costmap</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../4.slam_nav/navigation_theory.html#amcl">AMCL</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../4.slam_nav/navigation_theory.html#dynamic-window-approach-dwa">Dynamic Window Approach (DWA)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../4.slam_nav/mission.html">Mission</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/mission.html#constructing-a-map-as-a-team">Constructing a Map (as a Team)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/mission.html#mapping-the-constructed-map">Mapping the Constructed Map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/mission.html#executing-navigation">Executing Navigation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../4.slam_nav/mission.html#team-competition">Team Competition</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../4.slam_nav/discussion.html">Discussion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../4.slam_nav/qa.html">Q&amp;A session</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../5.robot_arm_ex/index.html">Robot Arm</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/index.html">Follow Along!</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/basic_control/index.html">Basic Robot Arm Control</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/basic_control/1.moving_arm.html">Moving the Robot Arm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/basic_control/2.motor_angle.html">Read Servo Motor Angle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/basic_control/3.motor_cont.html">Controlling Servo Motors</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/basic_control/4.dancing_arm.html">Dancing with the Robot Arm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/basic_control/5.teaching_arm.html">Robot Arm teaching</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/basic_control/6.gripper_control.html">Gripper Control</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/advanced_control/index.html">Advanced Robot Arm Control</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/advanced_control/1.track_color.html">Tracking a Color with the Robotic Arm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/advanced_control/2.tracking_face.html">Tracking a Face with the Robotic Arm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/follow_along/advanced_control/sound/index.html">Dancing With Music</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../5.robot_arm_ex/explanation.html">Overall Explanation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/explanation.html#robot-arm-movements">Robot Arm Movements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/explanation.html#tracking-a-color-or-a-face">Tracking a Color or a Face</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/explanation.html#sound-pygame-sound-libraries">Sound (PyGame Sound Libraries)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../5.robot_arm_ex/code_explanation/index.html">Code Explanation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/code_explanation/index.html#robot-arm-movements">Robot arm Movements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/code_explanation/index.html#basic-movements">Basic Movements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/code_explanation/index.html#reading-the-current-angle-of-the-servo">Reading the Current Angle of the Servo</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/code_explanation/index.html#teaching-the-robot-arm">Teaching the Robot Arm</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/code_explanation/index.html#tacking-a-color-or-a-face">Tacking a Color or a Face</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/code_explanation/index.html#tracking-a-color">Tracking a Color</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/code_explanation/index.html#tracking-a-face">Tracking a Face</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../5.robot_arm_ex/mission/index.html">Mission Project</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/mission/index.html#libraries-used-for-this-mission">Libraries used for this Mission</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/mission/index.html#mission-lib-custom-library">mission_lib custom Library</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../5.robot_arm_ex/mission/index.html#event-name-custom-library">event_name custom Library</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/mission/index.html#lets-start-the-mission">Lets Start the Mission!!!</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../5.robot_arm_ex/mission/index.html#pick-up-an-object-and-place-it-somewhere-else">Pick up an object and place it somewhere else!</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../5.robot_arm_ex/discussion.html">Discussion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../5.robot_arm_ex/qa.html">Q&amp;A session</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../6.cv/index.html">Computer Vision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../6.cv/realsense/index.html">Exercises Using RealSense Depth Camera</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../6.cv/realsense/1.follow_along/index.html">Follow Along!</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../6.cv/realsense/1.follow_along/1.exercise.html">Exercise 1: ASCII Depth Representation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../6.cv/realsense/1.follow_along/2.exercise.html">Exercise 2: OpenCV and Numpy integration</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../6.cv/realsense/1.follow_along/3.exercise.html">Exercise 3: Align Depth with Color</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../6.cv/realsense/1.follow_along/4.exercise.html">Exercise 4. Advanced Mode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../6.cv/realsense/2.theory.html">Depth Camera Theory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../6.cv/realsense/3.code_explanation.html">Code Explanation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../6.cv/realsense/discussion.html">Discussion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../6.cv/realsense/qa.html">Q&amp;A session</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../7.digital_twin/index.html">Digital Twin</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../7.digital_twin/1.follow_along.html">Follow Along!</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../7.digital_twin/1.follow_along.html#initialization">Initialization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../7.digital_twin/1.follow_along.html#import-the-virtual-environment-and-the-robot">Import the Virtual Environment and the Robot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../7.digital_twin/1.follow_along.html#test-the-virtual-movements">Test the Virtual Movements</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../7.digital_twin/1.follow_along.html#navigation">Navigation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../7.digital_twin/2.terminology/index.html">Explanation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../7.digital_twin/2.terminology/1.initial.html">Initialization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../7.digital_twin/2.terminology/1.initial.html#robot-tuning">Robot Tuning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../7.digital_twin/2.terminology/1.initial.html#robot-driving">Robot Driving</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../7.digital_twin/2.terminology/2.actiongraph.html">Action Graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../7.digital_twin/2.terminology/4.usd.html">Universal Scene Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../7.digital_twin/2.terminology/3.navigation.html">Navigation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../7.digital_twin/2.terminology/3.navigation.html#occupancy-map">Occupancy Map</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../7.digital_twin/2.terminology/5.warehouse.html">Warehouse Navigation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../7.digital_twin/2.terminology/5.warehouse.html#prerequisite">Prerequisite</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../7.digital_twin/2.terminology/5.warehouse.html#the-ros-navigation-setup">The ROS Navigation Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../7.digital_twin/2.terminology/5.warehouse.html#running-ros-navigation">Running ROS Navigation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../7.digital_twin/discussion.html">Discussion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../7.digital_twin/qa.html">Q&amp;A session</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../8.chat_gpt/index.html">ChatGPT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../8.chat_gpt/index.html#sample">Sample</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../8.chat_gpt/index.html#methods">Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../8.chat_gpt/index.html#limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../9.ai_kit/index.html">AI Kit</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../9.ai_kit/construction.html">Construction Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../9.ai_kit/mission.html">Mission</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../9.ai_kit/discussion.html">Discussion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../9.ai_kit/qa.html">Q&amp;A session</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Two-day Lecture</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../2_day_lecture/index.html">Coming Soon!</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Week Lecture</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../week_lecture/index.html">Coming Soon!</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Instructors Version</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">AI Training Examples</a></li>
          <li class="breadcrumb-item"><a href="index.html">Sematic Segmentation with FCN-ResNet18</a></li>
      <li class="breadcrumb-item active">Mission</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/lecture/2.ai_training/segmentation/4.mission.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mission">
<h1>Mission<a class="headerlink" href="#mission" title="Permalink to this headline"></a></h1>
<div style="background: #ffe5b4" class="admonition note custom">
    <p style="background: #ffbf00" class="admonition-title">
        Project Name: Custom Segmentation System
    </p>
    <div class="line-block">
        <div class="line"><strong>-</strong> This mission is an <strong>individual project</strong></div>
        <div class="line"><strong>-</strong> Create the custom segmetation program which utilizes zetabot camera.</div>
        <div class="line"><strong>-</strong> Within your individual computers, execute the following mission.  </div>
    </div>
</div><section id="writing-custom-segnet-program">
<h2>Writing Custom segNet Program<a class="headerlink" href="#writing-custom-segnet-program" title="Permalink to this headline"></a></h2>
<p>Similar to how we created a new python file in our team assignment, generate a new python file and name it <code class="docutils literal notranslate"><span class="pre">segmentation_camera.py</span></code>.</p>
<p>Create a new python file in the Jupyter Notebook Environment:</p>
<ul>
<li><p>Press the blue plus button on the top left corner of the web.</p>
<a class=""
               data-lightbox="group-b4454775-f92a-415c-8b78-8040d6753232"
               href="../../../_images/add_plus1.png"
               title=""
               data-title=""
               
               ><img src="../../../_images/add_plus1.png"
                     class=""
                     width="100%"
                     height="auto"
                     alt=""/>
                </a></li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<ul>
<li><p>Create a new python file by pressing the <code class="docutils literal notranslate"><span class="pre">Python</span> <span class="pre">File</span></code> button</p>
<a class=""
               data-lightbox="group-ff7166cf-e4bc-436a-94c1-6be98a171dbb"
               href="../../../_images/pick_python1.png"
               title=""
               data-title=""
               
               ><img src="../../../_images/pick_python1.png"
                     class=""
                     width="100%"
                     height="auto"
                     alt=""/>
                </a></li>
</ul>
<div class="line-block">
<div class="line"><br /></div>
</div>
<ul>
<li><p>Rename the untitiled python file to <code class="docutils literal notranslate"><span class="pre">segmentation_camera.py</span></code></p></li>
<li><p>On the new python file, import the libraries necessary. For our segmentation task, we need to import the Jetson inference library modules and jetson utility library modules</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">argparse</span></code>: This library contains modules that are responsbile for bringing and intitializing the flags or parameters set by the user when envoking the program.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sys</span></code>: this library allows us to manipulate/ utilize system functions within our python programs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">jetson_inference</span></code>: This library contains all the pre-built networks that can be used for inference task and a functions that would allow for custom models to be used for inference tasks.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">setNet</span></code>: We are importing segNet module for our segmentation task.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">jetson_utils</span></code>: This library contains modules that are responsible for processing input and output sources along with output stream methods. We will be importing the following modules:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">videoSource</span></code>: used to process input source (whether it is a camera, an image, or a video).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">videoOutput</span></code>: used to process the output stream.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cudaOverlay</span></code>: this module allows for overlay on the output stream.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cudaDeviceSynchronize</span></code>: This module allows for cuda devices and processes to synchronize.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">segnet_utils</span></code>: This library allows for buffer segmentation methods.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">from</span> <span class="nn">jetson_inference</span> <span class="kn">import</span> <span class="n">segNet</span>
<span class="kn">from</span> <span class="nn">jetson_utils</span> <span class="kn">import</span> <span class="n">videoSource</span><span class="p">,</span> <span class="n">videoOutput</span><span class="p">,</span> <span class="n">cudaOverlay</span><span class="p">,</span> <span class="n">cudaDeviceSynchronize</span>

<span class="kn">from</span> <span class="nn">segnet_utils</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</li>
<li><p>After all the libraries are imported, initialize the parser variable with <code class="docutils literal notranslate"><span class="pre">argparse.ArgumentParser</span></code> module.</p>
<p>For our mission, we must receive the network name, and Camera output channel name. Additionally we add our minor functinoality flags.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># parse the command line</span>
<span class="c1"># For our mission, We recieve the network name, and Camera name.</span>
<span class="c1"># Set up argument parser, so that command line parameters can be read within the program</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Segment a live camera stream using an semantic segmentation DNN.&quot;</span><span class="p">,</span>
                                <span class="n">formatter_class</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">RawTextHelpFormatter</span><span class="p">,</span>
                                <span class="n">epilog</span><span class="o">=</span><span class="n">segNet</span><span class="o">.</span><span class="n">Usage</span><span class="p">()</span> <span class="o">+</span> <span class="n">videoSource</span><span class="o">.</span><span class="n">Usage</span><span class="p">()</span> <span class="o">+</span> <span class="n">videoOutput</span><span class="o">.</span><span class="n">Usage</span><span class="p">())</span>

<span class="c1"># Major Functionality parameters (required from the user)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;input_CAMERA&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s1">&#39;?&#39;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;use csi://0 for Raspberry pi Camera&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--network&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;pre-trained model to load&quot;</span><span class="p">)</span>

<span class="c1"># Minor Functionality parameters (optional)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--filter-mode&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;point&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">],</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;filtering mode used during visualization, options are:</span><span class="se">\n</span><span class="s2">  &#39;point&#39; or &#39;linear&#39; (default: &#39;linear&#39;)&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--visualize&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;overlay,mask&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Visualization options (can be &#39;overlay&#39; &#39;mask&#39; &#39;overlay,mask&#39;&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--ignore-class&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="s2">&quot;void&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;optional name of class to ignore in the visualization results (default: &#39;void&#39;)&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--alpha&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mf">150.0</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;alpha blending value to use during overlay, between 0.0 and 255.0 (default: 150.0)&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;--stats&quot;</span><span class="p">,</span> <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;compute statistics about segmentation mask class output&quot;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Initialize opt variable to hold all the user-set flags in a list form. If the user has set no flags, terminate the program:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># If no parameter is given from the user, shut the program down</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_known_args</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">print_help</span><span class="p">()</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Initialize the necessary variables. Since we wish to infer a network with a camera and show the results with our output stream we will need:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">net</span></code> variable for holding the nvidia pre-built networks. For this mission we are using FCN-Resnet18-VOC (you may change this to FCN-ResNet18-Sun for indoor segmentation) network.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input</span></code> variable for handling the input stream. Using the <code class="docutils literal notranslate"><span class="pre">opt</span></code> variable created in our previous step, we will bring in input_CAMERA to set our videoSource.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">display</span></code> variable for handling the output stream. Although we are accessing the code remotely on our remote computer, the zetabot is equipped with a touch screen display. The display is set on <code class="docutils literal notranslate"><span class="pre">DISPLAY://0</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">buffer</span></code> variable for managing buffer.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the segmentation network</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">segNet</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>

<span class="c1"># set the alpha blending value</span>
<span class="n">net</span><span class="o">.</span><span class="n">SetOverlayAlpha</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>

<span class="c1"># create video sources &amp; outputs</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">videoSource</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">input_CAMERA</span><span class="p">,</span> <span class="n">argv</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">videoOutput</span><span class="p">(</span><span class="s2">&quot;DISPLAY://0&quot;</span><span class="p">,</span> <span class="n">argv</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">)</span>
<span class="c1"># create buffer manager</span>
<span class="n">buffers</span> <span class="o">=</span> <span class="n">segmentationBuffers</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>For this task we are utilizing our camera. On our previous trials, we had to to an inference on a single image. The program could recieve the one image infer it with the network and output a single result.</p>
<p>But with a camera, we need to repeatedly run the inference so that we may capture the incoming frames from the camera and output a constant stream of results.</p>
<ul>
<li><p>We may achieve this by running a while loop until an envoked output stream window is killed by the user.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># process frames until the user exits</span>
<span class="k">while</span> <span class="n">display</span><span class="o">.</span><span class="n">IsStreaming</span><span class="p">():</span>
</pre></div>
</div>
</li>
<li><p>Within the while loop:</p>
<ul>
<li><p>Capture the current frame from the camera, allocate buffer for the size of the camera and infer the image using the trained model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Capture each of the frames of camera</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">Capture</span><span class="p">()</span>

<span class="c1"># allocate buffers for this size image</span>
<span class="n">buffers</span><span class="o">.</span><span class="n">Alloc</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>

<span class="c1"># process the segmentation network</span>
<span class="n">net</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">ignore_class</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">ignore_class</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Overlay the resulting heatmap and mask with with the buffer.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate the overlay</span>
<span class="k">if</span> <span class="n">buffers</span><span class="o">.</span><span class="n">overlay</span><span class="p">:</span>
    <span class="n">net</span><span class="o">.</span><span class="n">Overlay</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">overlay</span><span class="p">,</span> <span class="n">filter_mode</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">filter_mode</span><span class="p">)</span>

<span class="c1"># generate the mask</span>
<span class="k">if</span> <span class="n">buffers</span><span class="o">.</span><span class="n">mask</span><span class="p">:</span>
    <span class="n">net</span><span class="o">.</span><span class="n">Mask</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="n">filter_mode</span><span class="o">=</span><span class="n">opt</span><span class="o">.</span><span class="n">filter_mode</span><span class="p">)</span>

<span class="c1"># composite the images</span>
<span class="k">if</span> <span class="n">buffers</span><span class="o">.</span><span class="n">composite</span><span class="p">:</span>
    <span class="n">cudaOverlay</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">overlay</span><span class="p">,</span> <span class="n">buffers</span><span class="o">.</span><span class="n">composite</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">cudaOverlay</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">mask</span><span class="p">,</span> <span class="n">buffers</span><span class="o">.</span><span class="n">composite</span><span class="p">,</span> <span class="n">buffers</span><span class="o">.</span><span class="n">overlay</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Render the result output and update the title bar of the output window.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># render the output image</span>
<span class="n">output</span><span class="o">.</span><span class="n">Render</span><span class="p">(</span><span class="n">buffers</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

<span class="c1"># update the title bar</span>
<span class="n">output</span><span class="o">.</span><span class="n">SetStatus</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:s}</span><span class="s2"> | Network </span><span class="si">{:.0f}</span><span class="s2"> FPS&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">network</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">GetNetworkFPS</span><span class="p">()))</span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section id="executing-the-custom-program">
<h2>Executing the Custom Program<a class="headerlink" href="#executing-the-custom-program" title="Permalink to this headline"></a></h2>
<ul class="simple">
<li><p>Open the <code class="docutils literal notranslate"><span class="pre">segmentation_camera.ipynb</span></code> notebook.</p></li>
</ul>
<a class=""
               data-lightbox="group-e5507aa2-b501-428f-bb15-474563169299"
               href="../../../_images/segmentation_camera1.png"
               title=""
               data-title=""
               
               ><img src="../../../_images/segmentation_camera1.png"
                     class=""
                     width="100%"
                     height="auto"
                     alt=""/>
                </a><div class="line-block">
<div class="line"><br /></div>
</div>
<ul>
<li><p>Run the cell code which initializes the input/ output stream of the environment as well as the CAMERA variable, which will be the flag that determines the input vairable for the program to be a camera stream.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">env</span> <span class="n">DISPLAY</span><span class="o">=</span><span class="p">:</span><span class="mi">0</span>
<span class="o">%</span><span class="n">env</span> <span class="n">csi</span><span class="o">=</span><span class="p">:</span><span class="mi">0</span>
<span class="o">%</span><span class="n">env</span> <span class="n">CAMERA</span><span class="o">=</span><span class="n">csi</span><span class="p">:</span><span class="o">//</span><span class="mi">0</span>
</pre></div>
</div>
</li>
<li><p>Check if your python notebook can read the python code you have written:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cat</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">zeta</span><span class="o">/</span><span class="n">notebook</span><span class="o">/</span><span class="s1">&#39;9. AI 실습예제&#39;</span><span class="o">/</span><span class="s1">&#39;segmentation_camera.py&#39;</span>
</pre></div>
</div>
</li>
<li><p>One important thing about the zetabot is that the Raspberry Pi camera is constantly running.</p>
<p>In order to use the camera for our task we must disable it first by running the following command:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>%%capture
!pm2 stop 5
</pre></div>
</div>
<p>This will allow the camera to be used for our program.</p>
</li>
<li><p>Execute the segmentation_camera python code.</p>
<p><em>Note</em> that we are setting our major functions,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--network</span></code>: to set which networks to use in our segmentation task.</p>
<ul>
<li><p>You may change the pre-trained networks to the previously discussed networks.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_CAMERA</span></code>: to set which input stream will be used for our task. It is being set to CAMERA environment variable which holds <code class="docutils literal notranslate"><span class="pre">csi://0</span></code> as a string.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>%%capture
!python3 /home/zeta/notebook/&#39;9. AI 실습예제&#39;/segmentation_camera.py --network=fcn-resnet18-voc $CAMERA
</pre></div>
</div>
</li>
<li><p>Be sure to turn the camera back online by:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>%%capture
!pm2 start 5
</pre></div>
</div>
</li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="3.coding_explanation.html" class="btn btn-neutral float-left" title="Coding Explanation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="5.discussion.html" class="btn btn-neutral float-right" title="Discussion" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-17821189-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-17821189-2', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>